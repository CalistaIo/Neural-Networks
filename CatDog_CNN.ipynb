{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "# Preprocess training set\n",
    "# Perform image augmentation to prevent overfitting\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, # rescale performs feature scaling\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)\n",
    "# Connect to training set\n",
    "# Convolutional neural network is trained and tested on batches of images\n",
    "training_set = train_datagen.flow_from_directory('../dataset/training_set',\n",
    "                                                   target_size=(64, 64),\n",
    "                                                   batch_size=32, # number of images in each batch\n",
    "                                                   class_mode='binary') # class_mode is either binary or categorical\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Connect to test set\n",
    "test_set = test_datagen.flow_from_directory('../dataset/test_set',\n",
    "                                           target_size=(64, 64), # must be same format as training data\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create convolutional neural network as sequence of layers\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# Convolutional layer\n",
    "# filters=no_of_feature_detectors, kernel_size=size_of_feature_detector(width/length), input_shape=(length, width, dim) (dim is 3 for colored images)\n",
    "# strides is kept to default of (1, 1)\n",
    "# input_shape is specified only for first convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "\n",
    "# Pooling layer\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full connection\n",
    "\n",
    "# Add hidden layer\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# Add output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile convolutional neural network\n",
    "# Use adam optimizer to perform stochastic gradient descent\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 106s 423ms/step - loss: 0.6789 - accuracy: 0.5702 - val_loss: 0.6368 - val_accuracy: 0.6270\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 0.6121 - accuracy: 0.6647 - val_loss: 0.5866 - val_accuracy: 0.6865\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 95s 379ms/step - loss: 0.5663 - accuracy: 0.7032 - val_loss: 0.5745 - val_accuracy: 0.7085\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 104s 417ms/step - loss: 0.5321 - accuracy: 0.7259 - val_loss: 0.5454 - val_accuracy: 0.7310\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 102s 409ms/step - loss: 0.5113 - accuracy: 0.7480 - val_loss: 0.5092 - val_accuracy: 0.7635\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 0.4883 - accuracy: 0.7649 - val_loss: 0.4994 - val_accuracy: 0.7685\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 99s 394ms/step - loss: 0.4611 - accuracy: 0.7751 - val_loss: 0.4750 - val_accuracy: 0.7760\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 0.4507 - accuracy: 0.7916 - val_loss: 0.4588 - val_accuracy: 0.7920\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 0.4306 - accuracy: 0.7970 - val_loss: 0.4622 - val_accuracy: 0.7900\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 98s 394ms/step - loss: 0.4307 - accuracy: 0.7981 - val_loss: 0.5284 - val_accuracy: 0.7475\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 100s 402ms/step - loss: 0.3976 - accuracy: 0.8169 - val_loss: 0.4994 - val_accuracy: 0.7765\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 98s 393ms/step - loss: 0.3867 - accuracy: 0.8213 - val_loss: 0.4745 - val_accuracy: 0.7765\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 98s 394ms/step - loss: 0.3768 - accuracy: 0.8294 - val_loss: 0.4962 - val_accuracy: 0.7795\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 101s 403ms/step - loss: 0.3675 - accuracy: 0.8307 - val_loss: 0.4592 - val_accuracy: 0.8030\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 102s 410ms/step - loss: 0.3414 - accuracy: 0.8514 - val_loss: 0.5179 - val_accuracy: 0.7865\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 100s 400ms/step - loss: 0.3296 - accuracy: 0.8575 - val_loss: 0.5151 - val_accuracy: 0.7800\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 98s 391ms/step - loss: 0.3214 - accuracy: 0.8600 - val_loss: 0.4879 - val_accuracy: 0.8010\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 0.2999 - accuracy: 0.8698 - val_loss: 0.5136 - val_accuracy: 0.7960\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 95s 382ms/step - loss: 0.2934 - accuracy: 0.8758 - val_loss: 0.5165 - val_accuracy: 0.7935\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 0.2733 - accuracy: 0.8856 - val_loss: 0.5580 - val_accuracy: 0.7865\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 98s 392ms/step - loss: 0.2563 - accuracy: 0.8949 - val_loss: 0.5083 - val_accuracy: 0.8075\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 104s 416ms/step - loss: 0.2445 - accuracy: 0.8966 - val_loss: 0.5001 - val_accuracy: 0.7975\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 102s 407ms/step - loss: 0.2267 - accuracy: 0.9080 - val_loss: 0.5791 - val_accuracy: 0.7750\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 104s 414ms/step - loss: 0.2153 - accuracy: 0.9130 - val_loss: 0.5484 - val_accuracy: 0.7985\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 105s 421ms/step - loss: 0.2021 - accuracy: 0.9164 - val_loss: 0.5467 - val_accuracy: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207a09f9bc8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train convolutional neural network on training set and evaluate it on test set\n",
    "cnn.fit(x=training_set, validation_data=test_set, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cats': 0, 'dogs': 1}\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "# Make single prediction\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Load image to predict\n",
    "# Image format must be same as training/test data\n",
    "test_image = image.load_img(path='../dataset/single_prediction/cat_or_dog_2.jpg', target_size=(64, 64))\n",
    "\n",
    "# Convert image to 2D array to input into predict()\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "# Image must be in batch so batch is added as extra (first) dimension\n",
    "# Perform feature scaling on image\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image = test_image / 255.0\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "# Check which binary output corresponds to which label\n",
    "print(training_set.class_indices)\n",
    "\n",
    "# First index refers to batch, second index refers to first (and only) image in that batch\n",
    "if (result[0][0] > 0.5):\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
